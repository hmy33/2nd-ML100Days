{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "y_train: (50000, 1)\n",
      "x_test: (10000, 32, 32, 3)\n",
      "y_test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "### load data\n",
    "(x_train_ori, y_train_ori), (x_test_ori, y_test_ori) = cifar10.load_data()\n",
    "print('x_train:', x_train_ori.shape)\n",
    "print('y_train:', y_train_ori.shape)\n",
    "print('x_test:', x_test_ori.shape)\n",
    "print('y_test:', y_test_ori.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing\n",
    "# normalize\n",
    "x_train = x_train_ori / 255\n",
    "x_test = x_test_ori / 255\n",
    "\n",
    "# label: ont-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train_ori)\n",
    "y_test = np_utils.to_categorical(y_test_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0809 00:20:10.283389 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0809 00:20:10.934851 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0809 00:20:10.944858 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0809 00:20:11.051934 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0809 00:20:11.053934 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0809 00:20:43.702119 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0809 00:20:44.210477 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0809 00:20:44.233497 17160 deprecation.py:506] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### define network\n",
    "def build_network(input_shape, output_units, num_neurons=[512], num_filters=[32, 64]):\n",
    "    input_layer = Input(input_shape)\n",
    "    x = input_layer\n",
    "    \n",
    "    for filters in num_filters:\n",
    "        x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=(3, 3), activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    for units in num_neurons:\n",
    "        x = Dense(units=units, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "    out = Dense(units=output_units, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=[out])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = build_network(x_train.shape[1:], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 00:20:45.423339 17160 deprecation_wrapper.py:119] From c:\\users\\user\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0809 00:20:45.773588 17160 deprecation.py:323] From c:\\users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 1.8352 - acc: 0.4218 - val_loss: 1.4855 - val_acc: 0.5033\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 1.2331 - acc: 0.5691 - val_loss: 1.2375 - val_acc: 0.5709\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 1.0236 - acc: 0.6412 - val_loss: 1.0376 - val_acc: 0.6363\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.9069 - acc: 0.6821 - val_loss: 0.9130 - val_acc: 0.6815\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.8216 - acc: 0.7111 - val_loss: 0.7820 - val_acc: 0.7319\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.7510 - acc: 0.7346 - val_loss: 0.7499 - val_acc: 0.7390\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6946 - acc: 0.7535 - val_loss: 0.7263 - val_acc: 0.7465\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6517 - acc: 0.7690 - val_loss: 0.7620 - val_acc: 0.7306\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6106 - acc: 0.7836 - val_loss: 0.6661 - val_acc: 0.7681\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.5774 - acc: 0.7957 - val_loss: 0.7105 - val_acc: 0.7603\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.5440 - acc: 0.8071 - val_loss: 0.6334 - val_acc: 0.7849\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.5138 - acc: 0.8208 - val_loss: 0.6591 - val_acc: 0.7797\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.4888 - acc: 0.8253 - val_loss: 0.6737 - val_acc: 0.7718\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.4624 - acc: 0.8351 - val_loss: 0.6087 - val_acc: 0.7953\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.4405 - acc: 0.8436 - val_loss: 0.6127 - val_acc: 0.7930\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.4209 - acc: 0.8518 - val_loss: 0.6166 - val_acc: 0.7997\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.4034 - acc: 0.8570 - val_loss: 0.5939 - val_acc: 0.8041\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.3794 - acc: 0.8641 - val_loss: 0.5806 - val_acc: 0.8086\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.3612 - acc: 0.8699 - val_loss: 0.5812 - val_acc: 0.8063\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.3481 - acc: 0.8763 - val_loss: 0.5847 - val_acc: 0.8074\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.8, min_lr=1e-6, monitor='val_loss', patience=3)\n",
    "callbacks = [earlystop, reduce_lr]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
